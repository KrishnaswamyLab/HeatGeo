[
  {
    "objectID": "cheb.html",
    "href": "cheb.html",
    "title": "Chebyshev approximation",
    "section": "",
    "text": "This page contains all functions related to the Chebyshev approximation of the heat kernel. They are slighly modified from Fast-Multiscale-Diffusion-on-Graphs. See also the related paper.\n\nsource\n\nexpm_multiply\n\n expm_multiply (L, X, phi, tau, K=None, err=1e-32)\n\n\nsource\n\n\ncompute_chebychev_coeff_all\n\n compute_chebychev_coeff_all (phi, tau, K)\n\nCompute the K+1 Chebychev coefficients for our functions.\n\nsource\n\n\nreverse_bound\n\n reverse_bound (f, phi, x, tau, err)\n\nReturns the minimal K such that f(phi, x, tau, K) &lt;= err.\n\nsource\n\n\nget_bound_bergamaschi_specific\n\n get_bound_bergamaschi_specific (phi, x, tau, K)\n\n\nsource\n\n\nget_bound_bergamaschi_generic\n\n get_bound_bergamaschi_generic (phi, x, tau, K)\n\n\nsource\n\n\nE\n\n E (K, C)\n\n\nsource\n\n\nget_bound_eta_specific\n\n get_bound_eta_specific (phi, x, tau, K)\n\n\nsource\n\n\nget_bound_eta_generic\n\n get_bound_eta_generic (phi, x, tau, K)\n\n\nsource\n\n\nget_bound_eps_generic\n\n get_bound_eps_generic (phi, x, tau, K)\n\n\nsource\n\n\ng\n\n g (K, C)",
    "crumbs": [
      "Chebyshev approximation"
    ]
  },
  {
    "objectID": "other_emb.html",
    "href": "other_emb.html",
    "title": "Other methods",
    "section": "",
    "text": "These methods requires additional packages that are installed with the development version of our package.\n\nsource\n\nRandWalkGeo\n\n RandWalkGeo (knn:int, anisotropy:int=0, decay:int=40, n_pca:int=40,\n              tau:int=10, emb_dim:int=2, filter_method:str='exact',\n              order:int=32, lap_type:str='normalized',\n              log_normalize:bool=False, scale_factor:float=1,\n              denoising:bool=False, n_ref:int=50, n_svd:int=50,\n              graph_type:str='alpha')\n\nHeatGeo with a random walk matrix instead of Heat kernel.\n\nsource\n\n\nDiffusionMap\n\n DiffusionMap (knn:int=0, decay:int=40, n_pca:int=40, tau:float=1,\n               emb_dim:int=2, anisotropy:int=0, graph_type:str='alpha',\n               **kwargs)\n\nDiffusion Map embedding with different graph construction.\n\nsource\n\n\nShortestPath\n\n ShortestPath (knn:int, anisotropy:int=0, decay:int=40, n_pca:int=40,\n               graph_type:str='alpha', **kwargs)\n\nShortest path embedding with different graph construction.\n\nsource\n\n\nPhateBasic\n\n PhateBasic (knn:int, anisotropy:int=0, decay:int=40, n_pca:int=40,\n             tau:Union[int,str]='auto', emb_dim:int=2)\n\nWrapper for PHATE.",
    "crumbs": [
      "Other methods"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Start with HeatGeo",
    "section": "",
    "text": "The Heat-Geodesic embedding preserves the heat-geodesic dissimilarity defined as \\[\nd_t(x_i,x_j) = \\bigg[ -4t \\log (\\mathbf{H}_t)_{ij} - \\sigma 4 t \\log(\\mathbf{V})_{ij} \\bigg] ^{1/2},\n\\] where \\(\\mathbf{H}_t\\) is a heat kernel on a graph, and \\(\\mathbf{V}\\) is a volume regularization term. This dissimilarity is inspired by Varadhan’s formula which relates the heat kernel to the geodesic distance on a manifold. For more details on the heat-geodesic dissimilarity read our preprint A Heat Diffusion Perspective on Geodesic Preserving Dimensionality Reduction.",
    "crumbs": [
      "Start with HeatGeo"
    ]
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "Start with HeatGeo",
    "section": "Install",
    "text": "Install\nThe package is available on PyPI, you can install it by running\npip install heatgeo\nTo reproduce the results in experiments/ or try the embeddings with different graph constructions, you need additional packages that can be installed via the development version. In this case run\npip install heatgeo['dev']\nWe provide an example below.",
    "crumbs": [
      "Start with HeatGeo"
    ]
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "Start with HeatGeo",
    "section": "How to use",
    "text": "How to use\nTo create the embedding of a dataset data, run\nfrom heatgeo.embedding import HeatGeo\nemb_op = HeatGeo(knn=5)\nemb = emb_op.fit_transform(data)\nWe provide a Google colab example on the swiss roll \nThe directory experiments contains code to reproduce our main results. We used hydra, the parameters can be changed in config or directly in the CLI. In notebooks, we provide examples on toy datasets.",
    "crumbs": [
      "Start with HeatGeo"
    ]
  },
  {
    "objectID": "index.html#contributing",
    "href": "index.html#contributing",
    "title": "Start with HeatGeo",
    "section": "Contributing",
    "text": "Contributing\nWe are using nbdev for this package and the documentation. See this introduction to start using nbdev. The code and documentation should be modified in the notebooks nbs/, then run nbdev_prepare before a commit. This command will export the notebooks to .py files in heatgeo, it will also clean the metadata, and run some test. The page will then automatically be deployed through GitHub actions.",
    "crumbs": [
      "Start with HeatGeo"
    ]
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "Start with HeatGeo",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThis repository is a simplified version of a larger codebase used for development. It loses the original commit history which contains contributions from other authors of the paper. This repository uses or modify code from the PHATE implementation, and the Chebychev polynomials implementation of the paper Fast Multiscale Diffusion on Graphs.",
    "crumbs": [
      "Start with HeatGeo"
    ]
  },
  {
    "objectID": "mds.html",
    "href": "mds.html",
    "title": "MDS",
    "section": "",
    "text": "source\n\nembed_MDS\n\n embed_MDS (X, ndim=2, seed=2, solver='sgd', how='metric',\n            input_is_dist=True, distance_metric='euclidean',\n            mds_weights=None)\n\n\nsource\n\n\nsmacof\n\n smacof (D, n_components=2, metric=True, init=None, random_state=None,\n         verbose=0, max_iter=3000, eps=1e-06, n_jobs=1)\n\nMetric and non-metric MDS using SMACOF Parameters ———- D : array-like, shape=[n_samples, n_samples] pairwise distances n_components : int, optional (default: 2) number of dimensions in which to embed D metric : bool, optional (default: True) Use metric MDS. If False, uses non-metric MDS init : array-like or None, optional (default: None) Initialization state random_state : int, RandomState or None, optional (default: None) numpy random state verbose : int or bool, optional (default: 0) verbosity max_iter : int, optional (default: 3000) maximum iterations eps : float, optional (default: 1e-6) stopping criterion Returns ——- Y : array-like, shape=[n_samples, n_components] embedded data\n\nsource\n\n\nsgd\n\n sgd (D, w=None, n_components=2, random_state=None, init=None)\n\nMetric MDS using stochastic gradient descent Parameters ———- D : array-like, shape=[n_samples, n_samples] pairwise distances n_components : int, optional (default: 2) number of dimensions in which to embed D random_state : int or None, optional (default: None) numpy random state init : array-like or None Initialization algorithm or state to use for MMDS Returns ——- Y : array-like, embedded data [n_sample, ndim]\n\nsource\n\n\nclassic\n\n classic (D, n_components=2, random_state=None)\n\nFast CMDS using random SVD Parameters ———- D : array-like, shape=[n_samples, n_samples] pairwise distances n_components : int, optional (default: 2) number of dimensions in which to embed D random_state : int, RandomState or None, optional (default: None) numpy random state Returns ——- Y : array-like, embedded data [n_sample, ndim]",
    "crumbs": [
      "MDS"
    ]
  },
  {
    "objectID": "graph.html",
    "href": "graph.html",
    "title": "Graph selection",
    "section": "",
    "text": "By default we use the alpha-decay kernel from PHATE. We implemented other types of kernels, to use them you need to install our package with [dev].\n\nsource\n\nget_umap_graph\n\n get_umap_graph (X, knn=5, **kwargs)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nX\n\n\n\n\n\nknn\nint\n5\nknn default to 15 in UMAP\n\n\nkwargs\n\n\n\n\n\n\n\nsource\n\n\nget_scanpy_graph\n\n get_scanpy_graph (X, knn=5, **kwargs)\n\n\nsource\n\n\nget_alpha_decay_graph\n\n get_alpha_decay_graph (X, knn:int=5, decay:float=40.0,\n                        anisotropy:float=0, n_pca:int=None, **kwargs)\n\n\nsource\n\n\nget_knn_graph\n\n get_knn_graph (X, knn=5, **kwargs)\n\n\nsource\n\n\ndiff_aff\n\n diff_aff (graph)\n\nCompute the diffusion affinity for a pygsp graph.\n\nsource\n\n\nkernel_degree\n\n kernel_degree (graph)\n\nCompute the kernel degree for a pygsp graph.\n\nsource\n\n\ndiff_op\n\n diff_op (graph)\n\nCompute the diffusion operator for a pygsp graph.",
    "crumbs": [
      "Graph selection"
    ]
  },
  {
    "objectID": "embedding.html",
    "href": "embedding.html",
    "title": "Heat Geo embedding",
    "section": "",
    "text": "In this page we define the Heat Geo embedding class HeatGeo and the BaseEmb class.\nThe main parameters of HeatGeo are\n\nthe number of neighbors knn considered to build the graph,\nthe diffusion time tau which can be set to \"auto\" or fixed to any positive real number\ndenoise_regul a float in [0,1], which corresponds to \\(\\rho\\) in the paper with \\(\\rho=1\\) uses only the triplet distance,\nharnack_regul is the weight parameter for the volume term in Def. 4.1. If it is too large all points will collapse together, we suggest using values in [0,2].\n\n\n\n\nEmbeddings on PBMC for different denoise_regul\n\n\n\nsource\n\nHeatGeo\n\n HeatGeo (knn:int, anisotropy:int=0, decay:int=40, n_pca:int=40,\n          tau:int=10, emb_dim:int=2, filter_method:str='mar',\n          order:int=32, lap_type:str='normalized', tau_min:float=0.1,\n          tau_max:float=200, n_tau:int=1, log_normalize:bool=False,\n          scale_factor:float=1.0, denoising:bool=False,\n          graph_type:str='alpha', truncation_type:Optional[str]=None,\n          truncation_arg:Optional[str]=None,\n          treshold_type:Optional[str]=None, harnack_regul:float=0,\n          norm_treshold:bool=True, mds_weights_type:Optional[str]=None,\n          mds_weights_args:Optional[str]=None, denoise_regul:float=0.0)\n\nBase class for embedding methods.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nknn\nint\n\n\n\n\nanisotropy\nint\n0\n\n\n\ndecay\nint\n40\n\n\n\nn_pca\nint\n40\n\n\n\ntau\nint\n10\n\n\n\nemb_dim\nint\n2\n\n\n\nfilter_method\nstr\nmar\n\n\n\norder\nint\n32\n\n\n\nlap_type\nstr\nnormalized\n\n\n\ntau_min\nfloat\n0.1\n\n\n\ntau_max\nfloat\n200\n\n\n\nn_tau\nint\n1\n\n\n\nlog_normalize\nbool\nFalse\n\n\n\nscale_factor\nfloat\n1.0\n\n\n\ndenoising\nbool\nFalse\n\n\n\ngraph_type\nstr\nalpha\n\n\n\ntruncation_type\nOptional\nNone\n\n\n\ntruncation_arg\nOptional\nNone\n\n\n\ntreshold_type\nOptional\nNone\n“min” or “max”\n\n\nharnack_regul\nfloat\n0\nHarnack regularization parameter, between 0 and 1.\n\n\nnorm_treshold\nbool\nTrue\n\n\n\nmds_weights_type\nOptional\nNone\n\n\n\nmds_weights_args\nOptional\nNone\n“heat_kernel”, “inv_dist”,“gaussian_dist”\n\n\ndenoise_regul\nfloat\n0.0\n\n\n\n\n\nsource\n\n\nBaseEmb\n\n BaseEmb (knn:int, anisotropy:int=0, decay:int=40, n_pca:int=40,\n          tau:Union[int,str]='auto', emb_dim:int=2, order:int=32,\n          random_state:int=42, scale_factor:float=2.0, tau_min:float=0.1,\n          tau_max:float=1.0, n_tau:int=1, n_landmarks:Optional[int]=None,\n          solver:str='sgd', lap_type:str='normalized',\n          filter_method:str='pygsp', graph_type:str='alpha',\n          mds_weights:Optional[str]=None)\n\nBase class for embedding methods.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nknn\nint\n\nnumber of nearest neighbors\n\n\nanisotropy\nint\n0\nanisotropy parameter in the diffusion kernel\n\n\ndecay\nint\n40\ndecay parameter in the diffusion kernel\n\n\nn_pca\nint\n40\nnumber of principal components to use for knn estimation\n\n\ntau\nUnion\nauto\ndiffusion time\n\n\nemb_dim\nint\n2\nembedding dimension\n\n\norder\nint\n32\norder of the Chebyshev approximation, or steps in Euler’s method\n\n\nrandom_state\nint\n42\nrandom state for the embedding\n\n\nscale_factor\nfloat\n2.0\npower when computing the distance matrix\n\n\ntau_min\nfloat\n0.1\nminimum diffusion time\n\n\ntau_max\nfloat\n1.0\nmaximum diffusion time\n\n\nn_tau\nint\n1\nnumber of diffusion times for entropy.\n\n\nn_landmarks\nOptional\nNone\n\n\n\nsolver\nstr\nsgd\nsolver to use for MDS\n\n\nlap_type\nstr\nnormalized\ntype of Laplacian to use for the graph \"normalized\" or \"combinatorial\"\n\n\nfilter_method\nstr\npygsp\nmethod to use for Heat approx. \"pygsp\" or \"euler\", \"mar\"\n\n\ngraph_type\nstr\nalpha\ntype of graph to use for the embedding \"knn\" or \"alpha\" or scanpy\n\n\nmds_weights\nOptional\nNone\nweights to use for MDS",
    "crumbs": [
      "Heat Geo embedding"
    ]
  },
  {
    "objectID": "heat_filter.html",
    "href": "heat_filter.html",
    "title": "Heat kernel approximations",
    "section": "",
    "text": "This page includes two methods to approximate the heat kernel. Both methods are wrapped in HeatFilter. By default we use the Chebyshev polynomials, but we can also use the Backward Euler methods with Cholesky decomposition.\nThe important parameters of HeatFilter are\n\nThe order of polynomials degree (or discretization steps if using Euler), by default we use order=32 (the same as pygsp).\nThe diffusion time tau.\n\nIn practice, we one can try a smaller order as it can make the algorithm faster, while maintaining good accuracy.\n\n\n\nDiffusion of Dirac on a path graph\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe backward Euler approximation could be made faster with scikit_sparse, but we currently have dependencies issues with this packages.\n\n\n\nsource\n\nHeatFilter\n\n HeatFilter (graph:Any, tau:float, order:int, method:str)\n\nWrapper for the approximation of the heat kernel.\n\n\n\n\nType\nDetails\n\n\n\n\ngraph\nAny\nGraph object\n\n\ntau\nfloat\nDiffusion time\n\n\norder\nint\nDegree or numver of steps\n\n\nmethod\nstr\nfilter \"pygsp\", \"mar\", \"euler\"\n\n\nReturns\nCallable\n\n\n\n\n\nsource\n\n\nHeatEuler\n\n HeatEuler (L, t, K)\n\nImplicit Euler discretization of the heat equation using Cholesky prefactorization.",
    "crumbs": [
      "Heat kernel approximations"
    ]
  },
  {
    "objectID": "utils.html",
    "href": "utils.html",
    "title": "Utils functions",
    "section": "",
    "text": "source\n\nget_optimal_heat\n\n get_optimal_heat (emb_op, tau_max:float=50, n_tau:int=20)\n\n*Select the optimal tau for the heat kernel.\nOptimal tau is found using Checbyshev approximation.*\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nemb_op\n\n\n\n\n\ntau_max\nfloat\n50\n\n\n\nn_tau\nint\n20\n\n\n\nReturns\nH: np.array (n_nodes, n_nodes)\n\nHeat kernel with optimal tau.\n\n\n\n\nsource\n\n\ntime_entropy\n\n time_entropy (H)\n\n\nsource\n\n\ninterpolate\n\n interpolate (x0, x1, n_steps)",
    "crumbs": [
      "Utils functions"
    ]
  }
]