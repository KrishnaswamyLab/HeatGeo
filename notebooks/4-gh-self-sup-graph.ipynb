{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "%matplotlib inline\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, ChebConv\n",
    "import numpy as np\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "import pygsp\n",
    "import seaborn as sns\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from src.embedding import EmbHeatGeo\n",
    "from src.mds import embed_MDS\n",
    "from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import ChebConv\n",
    "class ChebGCN(torch.nn.Module):\n",
    "    def __init__(self,hidden_channels, output_dim=20 ,K=5):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234567)\n",
    "        self.conv1 = ChebConv(data.num_features, hidden_channels, K=K)\n",
    "        self.conv2 = ChebConv(hidden_channels, output_dim, K=K)\n",
    "    \n",
    "    def graph_diffusion(self,x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.graph_diffusion(x,edge_index)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.softmax(x,dim=1)\n",
    "        return x\n",
    "\n",
    "model = ChebGCN(hidden_channels=16,K=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = to_dense_adj(data.edge_index).squeeze(0)\n",
    "graph = pygsp.graphs.Graph(adj.cpu().detach().numpy(), lap_type=\"normalized\")\n",
    "graph.estimate_lmax()\n",
    "tau = np.geomspace(0.5, 100, 10)\n",
    "n = adj.shape[0]\n",
    "filt = pygsp.filters.Heat(graph, tau=tau)\n",
    "heat_kernel = filt.filter(np.eye(n), order=30).reshape(\n",
    "            n, n, -1\n",
    "        )\n",
    "heat_kernel[heat_kernel < 0] = 0\n",
    "multi_geo = [\n",
    "            np.sqrt(-4 * tau[i] * np.log(heat_kernel[:, :, i] + 1e-16)) ** 2\n",
    "            for i in range(len(tau))\n",
    "        ]\n",
    "weights = 1 - tau / tau.sum()\n",
    "w_t = weights.sum()\n",
    "weights = weights / w_t if w_t > 0 else None\n",
    "dist = torch.from_numpy(np.average(multi_geo, axis=0, weights=weights)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Loss: 1971548.6250\n",
      "Epoch: 005, Loss: 0.0786\n",
      "Epoch: 010, Loss: 1971373.2500\n",
      "Epoch: 010, Loss: 0.0714\n",
      "Epoch: 015, Loss: 1971062.1250\n",
      "Epoch: 015, Loss: 0.0500\n",
      "Epoch: 020, Loss: 1970699.8750\n",
      "Epoch: 020, Loss: 0.0429\n",
      "Epoch: 025, Loss: 1970522.7500\n",
      "Epoch: 025, Loss: 0.0357\n",
      "Epoch: 030, Loss: 1970215.2500\n",
      "Epoch: 030, Loss: 0.0929\n",
      "Epoch: 035, Loss: 1970089.5000\n",
      "Epoch: 035, Loss: 0.1143\n",
      "Epoch: 040, Loss: 1969975.3750\n",
      "Epoch: 040, Loss: 0.0714\n",
      "Epoch: 045, Loss: 1969879.6250\n",
      "Epoch: 045, Loss: 0.0714\n",
      "Epoch: 050, Loss: 1969788.3750\n",
      "Epoch: 050, Loss: 0.0786\n",
      "Epoch: 055, Loss: 1969682.7500\n",
      "Epoch: 055, Loss: 0.1000\n",
      "Epoch: 060, Loss: 1969622.6250\n",
      "Epoch: 060, Loss: 0.0929\n",
      "Epoch: 065, Loss: 1969571.3750\n",
      "Epoch: 065, Loss: 0.1143\n",
      "Epoch: 070, Loss: 1969612.1250\n",
      "Epoch: 070, Loss: 0.1214\n",
      "Epoch: 075, Loss: 1969592.1250\n",
      "Epoch: 075, Loss: 0.1357\n",
      "Epoch: 080, Loss: 1969546.7500\n",
      "Epoch: 080, Loss: 0.1214\n",
      "Epoch: 085, Loss: 1969562.3750\n",
      "Epoch: 085, Loss: 0.1143\n",
      "Epoch: 090, Loss: 1969584.1250\n",
      "Epoch: 090, Loss: 0.1357\n",
      "Epoch: 095, Loss: 1969505.3750\n",
      "Epoch: 095, Loss: 0.1357\n"
     ]
    }
   ],
   "source": [
    "# Trained to match heat-geodesic distances. \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "def train():\n",
    "      train_idx = np.ix_(data.train_mask, data.train_mask)\n",
    "      model.train()\n",
    "      optimizer.zero_grad()  # Clear gradients.\n",
    "      out = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "      dist_pred = torch.cdist(out,out)\n",
    "      loss = criterion(dist_pred[train_idx], dist[train_idx])  # Compute the loss solely based on the training nodes.\n",
    "      loss.backward()  # Derive gradients.\n",
    "      optimizer.step()  # Update parameters based on gradients.\n",
    "      return loss\n",
    "\n",
    "def train_class_loss():\n",
    "      model.eval()\n",
    "      out = model(data.x, data.edge_index)\n",
    "      pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "      test_correct = pred[data.train_mask] == data.y[data.train_mask]  # Check against ground-truth labels.\n",
    "      test_acc = int(test_correct.sum()) / int(data.train_mask.sum())  # Derive ratio of correct predictions.\n",
    "      return test_acc\n",
    "\n",
    "for epoch in range(1, 100):\n",
    "    loss = train()\n",
    "    loss_class_train = train_class_loss()\n",
    "    if epoch % 5 == 0:\n",
    "      print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "      print(f'Epoch: {epoch:03d}, Loss: {loss_class_train:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relative heat-geodesic distance as node feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment feature with 0. \n",
    "zeros = torch.zeros((data.num_nodes,1))\n",
    "data.x = torch.hstack((data.x,zeros))\n",
    "data.num_features = data.x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234567)\n",
    "        self.conv1 = GCNConv(data.num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 050, Loss: 1.0662\n",
      "Epoch: 050, Loss test: 0.7750\n",
      "Epoch: 100, Loss: 0.5359\n",
      "Epoch: 100, Loss test: 0.7920\n",
      "Epoch: 150, Loss: 0.4030\n",
      "Epoch: 150, Loss test: 0.7970\n",
      "Epoch: 200, Loss: 0.3381\n",
      "Epoch: 200, Loss test: 0.7920\n",
      "Epoch: 250, Loss: 0.2531\n",
      "Epoch: 250, Loss test: 0.7870\n",
      "Epoch: 300, Loss: 0.2290\n",
      "Epoch: 300, Loss test: 0.7900\n",
      "Epoch: 350, Loss: 0.2317\n",
      "Epoch: 350, Loss test: 0.7870\n",
      "Epoch: 400, Loss: 0.2140\n",
      "Epoch: 400, Loss test: 0.7900\n",
      "Epoch: 450, Loss: 0.2206\n",
      "Epoch: 450, Loss test: 0.8020\n",
      "Epoch: 500, Loss: 0.1972\n",
      "Epoch: 500, Loss test: 0.8040\n"
     ]
    }
   ],
   "source": [
    "model = GCN(hidden_channels=16)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "      model.train()\n",
    "      optimizer.zero_grad()  # Clear gradients.\n",
    "      out = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
    "      loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
    "      loss.backward()  # Derive gradients.\n",
    "      optimizer.step()  # Update parameters based on gradients.\n",
    "      return loss\n",
    "\n",
    "def test():\n",
    "      model.eval()\n",
    "      out = model(data.x, data.edge_index)\n",
    "      pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "      test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n",
    "      test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n",
    "      return test_acc\n",
    "\n",
    "\n",
    "for epoch in range(1, 501):\n",
    "    loss = train()\n",
    "    if epoch % 50 ==0:\n",
    "      loss_test = test()\n",
    "      print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "      print(f'Epoch: {epoch:03d}, Loss test: {loss_test:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/g/guillaume.huguet/.conda/envs/metric_emb/lib/python3.10/site-packages/graphtools/graphs.py:290: RuntimeWarning: Detected zero distance between 11 pairs of samples. Consider removing duplicates to avoid errors in downstream processing.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# with relative heat distance.\n",
    "data = dataset[0]\n",
    "emb_op = EmbHeatGeo(knn=10)\n",
    "emb_op.fit(data.x.detach().numpy())\n",
    "emb_op.metric_computation(data.x.detach().numpy(), n_tau=2)\n",
    "relative_dist = torch.from_numpy(emb_op.get_relative_dist()).unsqueeze(1).float()\n",
    "relative_dist /= relative_dist.max()\n",
    "data.x = torch.hstack((data.x,relative_dist))\n",
    "data.num_features = data.x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 050, Loss: 1.2026\n",
      "Epoch: 050, Loss test: 0.7770\n",
      "Epoch: 100, Loss: 0.5699\n",
      "Epoch: 100, Loss test: 0.7970\n",
      "Epoch: 150, Loss: 0.4386\n",
      "Epoch: 150, Loss test: 0.7970\n",
      "Epoch: 200, Loss: 0.3837\n",
      "Epoch: 200, Loss test: 0.7930\n",
      "Epoch: 250, Loss: 0.3055\n",
      "Epoch: 250, Loss test: 0.7960\n",
      "Epoch: 300, Loss: 0.2686\n",
      "Epoch: 300, Loss test: 0.8050\n",
      "Epoch: 350, Loss: 0.2344\n",
      "Epoch: 350, Loss test: 0.7890\n",
      "Epoch: 400, Loss: 0.2276\n",
      "Epoch: 400, Loss test: 0.7950\n",
      "Epoch: 450, Loss: 0.2399\n",
      "Epoch: 450, Loss test: 0.8060\n",
      "Epoch: 500, Loss: 0.1981\n",
      "Epoch: 500, Loss test: 0.7990\n"
     ]
    }
   ],
   "source": [
    "model = GCN(hidden_channels=16)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "for epoch in range(1, 501):\n",
    "    loss = train()\n",
    "    if epoch % 50 ==0:\n",
    "      loss_test = test()\n",
    "      print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "      print(f'Epoch: {epoch:03d}, Loss test: {loss_test:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4a32b8ce1d8a7cc8940ec0fbf84ac7f0e06291324aa09cbfc1497fc150849df3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
