{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.knn_methods import KNNClassifier\n",
    "from src.dataset import SwissRoll\n",
    "import pandas as pd\n",
    "import graphtools as gt\n",
    "import os\n",
    "import pickle\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "from src.sc_dataset import EBData, AdataTraj, MultiCiteSeq\n",
    "import numpy as np\n",
    "from src.embedding import new_HeatGeo\n",
    "from src.emd import earth_movers_distance,sinkhorn_mccann\n",
    "import ot\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "DATA_DIR = os.environ[\"SHARE_DATA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " adata\t\t\t       MNIST\n",
      " adata_ec1_v1.h5ad\t       models\n",
      " cfm_last.ckpt\t\t       multiome_gex_processed_training.h5ad\n",
      " cifar-10-batches-py\t       op_cite_inputs_0.h5ad\n",
      " cifar-10-python.tar.gz        op_cite_inputs_1.h5ad\n",
      " cifar10_stats.npz\t       op_cite_inputs_2.h5ad\n",
      " clark.npz\t\t       op_cite_inputs_3.h5ad\n",
      " eb_velocity_v5.npz\t       op_cite_inputs.h5ad\n",
      " fid_stats_cifar10_train.npz  'open?id=14UB27-Spi8VjZYKST3ZcT8YVhAluiFWI'\n",
      " gaussians_20dim_back.pkl      op_train_multi_targets_0.h5ad\n",
      " gaussians_2dim_back.pkl       op_train_multi_targets_1.h5ad\n",
      " gaussians_50dim_back.pkl      op_train_multi_targets_2.h5ad\n",
      " gaussians_5dim_back.pkl       op_train_multi_targets.h5ad\n",
      " gh_last.ckpt\t\t       slurm-2958990.out\n",
      " last.ckpt\t\t       wot_v1.h5ad\n"
     ]
    }
   ],
   "source": [
    "! ls $DATA_DIR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load results and check in config files the knn, tau, and emb_dim.\n",
    "def load_results(path):\n",
    "    results = pd.DataFrame()\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for filename in files:\n",
    "            if filename.endswith(\"_0.pkl\"):\n",
    "                last_is_config = False\n",
    "                dt_current = pd.read_pickle(os.path.join(root, filename))\n",
    "                print(os.path.join(root, filename), \"res\")\n",
    "            if filename.endswith(\"config.yaml\") and not last_is_config:\n",
    "                last_is_config = True\n",
    "                config = OmegaConf.load(os.path.join(root, filename))\n",
    "                print(os.path.join(root, filename), \"config\")\n",
    "                dataset_name = config.dataset_name\n",
    "                config = config.model\n",
    "                order = 0 if \"order\" not in config else config.order\n",
    "                order = 0 if order is None else order\n",
    "                tau = 0 if \"tau\" not in config.keys() else config.tau\n",
    "                knn = 0 if \"knn\" not in config.keys() else config.knn\n",
    "                n_neighbors = 0 if \"n_neighbors\" not in config.keys() else config.n_neighbors\n",
    "                emb_dim = 0 if \"emb_dim\" not in config.keys() else config.emb_dim\n",
    "                n_components = 0 if \"n_components\" not in config.keys() else config.n_components\n",
    "                perplexity = 0 if \"perplexity\" not in config.keys() else config.perplexity\n",
    "                min_dist = 0 if \"min_dist\" not in config.keys() else config.min_dist\n",
    "                denoising = 0 if \"denoising\" not in config.keys() else config.denoising\n",
    "\n",
    "                # print(order, tau, knn, emb_dim, n_neighbors, n_components)\n",
    "                dt_current[\"order\"] = order\n",
    "                dt_current[\"tau\"] = tau\n",
    "                dt_current[\"knn\"] = knn\n",
    "                dt_current[\"emb_dim\"] = emb_dim\n",
    "                dt_current[\"n_neighbors\"] = n_neighbors\n",
    "                dt_current[\"n_components\"] = n_components\n",
    "                dt_current[\"dataset_name\"] = dataset_name\n",
    "                dt_current[\"perplexity\"] = perplexity\n",
    "                dt_current[\"min_dist\"] = min_dist\n",
    "                dt_current[\"denoising\"] = denoising\n",
    "                results = pd.concat([results,dt_current])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/network/scratch/g/guillaume.huguet/projects/metric_embeddings/logs/experiments/runs/interpolation/2023-05-09_18-49-48/ot_pred_EB_heat_geo_euler_0.pkl res\n",
      "/network/scratch/g/guillaume.huguet/projects/metric_embeddings/logs/experiments/runs/interpolation/2023-05-09_18-49-48/.hydra/config.yaml config\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Holdout</th>\n",
       "      <th>W1</th>\n",
       "      <th>W1</th>\n",
       "      <th>MMD RBF</th>\n",
       "      <th>MMD Linear</th>\n",
       "      <th>order</th>\n",
       "      <th>tau</th>\n",
       "      <th>knn</th>\n",
       "      <th>emb_dim</th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>n_components</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>min_dist</th>\n",
       "      <th>denoising</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>heat_geo_euler</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.677962</td>\n",
       "      <td>3.176551</td>\n",
       "      <td>0.221050</td>\n",
       "      <td>1.516787</td>\n",
       "      <td>30</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EB</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>heat_geo_euler</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.467934</td>\n",
       "      <td>2.362156</td>\n",
       "      <td>0.105140</td>\n",
       "      <td>0.531322</td>\n",
       "      <td>30</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EB</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>heat_geo_euler</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.432773</td>\n",
       "      <td>2.258759</td>\n",
       "      <td>0.091692</td>\n",
       "      <td>0.450973</td>\n",
       "      <td>30</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EB</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Method Seed Holdout        W1        W1   MMD RBF  MMD Linear  \\\n",
       "0  heat_geo_euler    0       1  1.677962  3.176551  0.221050    1.516787   \n",
       "1  heat_geo_euler    0       2  1.467934  2.362156  0.105140    0.531322   \n",
       "2  heat_geo_euler    0       3  1.432773  2.258759  0.091692    0.450973   \n",
       "\n",
       "   order   tau  knn  emb_dim  n_neighbors  n_components dataset_name  \\\n",
       "0     30  0.05   10        5            0             0           EB   \n",
       "1     30  0.05   10        5            0             0           EB   \n",
       "2     30  0.05   10        5            0             0           EB   \n",
       "\n",
       "   perplexity  min_dist  denoising  \n",
       "0           0         0      False  \n",
       "1           0         0      False  \n",
       "2           0         0      False  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = load_results(\"/network/scratch/g/guillaume.huguet/projects/metric_embeddings/logs/experiments/runs/interpolation\")\n",
    "res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING THE CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-09 15:04:11.624278: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-09 15:04:15.612174: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-09 15:04:15.612811: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-09 15:04:15.612832: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "In interpolation: Override 'model : heat_geo.yaml' is defined before 'experiment: None'.\n",
      "Overrides must be at the end of the defaults list\n",
      "\n",
      "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n"
     ]
    }
   ],
   "source": [
    "! python /network/scratch/g/guillaume.huguet/projects/metric_embeddings/ot_task.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mmd_rbf(X, Y, gamma=1.0):\n",
    "    \"\"\"MMD using rbf (gaussian) kernel (i.e., k(x,y) = exp(-gamma * ||x-y||^2 / 2))\n",
    "\n",
    "    Arguments:\n",
    "        X {[n_sample1, dim]} -- [X matrix]\n",
    "        Y {[n_sample2, dim]} -- [Y matrix]\n",
    "\n",
    "    Keyword Arguments:\n",
    "        gamma {float} -- [kernel parameter] (default: {1.0})\n",
    "\n",
    "    Returns:\n",
    "        [scalar] -- [MMD value]\n",
    "    \"\"\"\n",
    "    XX = metrics.pairwise.rbf_kernel(X, X, gamma)\n",
    "    YY = metrics.pairwise.rbf_kernel(Y, Y, gamma)\n",
    "    XY = metrics.pairwise.rbf_kernel(X, Y, gamma)\n",
    "    return XX.mean() + YY.mean() - 2 * XY.mean()\n",
    "\n",
    "def mmd_linear(X, Y):\n",
    "    \"\"\"MMD using linear kernel (i.e., k(x,y) = <x,y>)\n",
    "    Note that this is not the original linear MMD, only the reformulated and faster version.\n",
    "    The original version is:\n",
    "        def mmd_linear(X, Y):\n",
    "            XX = np.dot(X, X.T)\n",
    "            YY = np.dot(Y, Y.T)\n",
    "            XY = np.dot(X, Y.T)\n",
    "            return XX.mean() + YY.mean() - 2 * XY.mean()\n",
    "\n",
    "    Arguments:\n",
    "        X {[n_sample1, dim]} -- [X matrix]\n",
    "        Y {[n_sample2, dim]} -- [Y matrix]\n",
    "\n",
    "    Returns:\n",
    "        [scalar] -- [MMD value]\n",
    "    \"\"\"\n",
    "    delta = X.mean(0) - Y.mean(0)\n",
    "    return delta.dot(delta.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/network/scratch/a/alexander.tong/trajectory-inference/data'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING the interpolation method\n",
    "#n_points = 1e10\n",
    "n_points = 2000\n",
    "#ds = EBData(n_points=n_points, random_state=42)\n",
    "#ds = MultiCiteSeq(data_file = \"op_train_multi_targets_0.h5ad\",n_points=n_points, random_state=42)\n",
    "ds = MultiCiteSeq(data_file = \"wot_v1.h5ad\",n_points=n_points, random_state=42)\n",
    "data, labels = ds.X, ds.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 100)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_time = np.unique(labels)\n",
    "hold_out = unique_time[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.  ,  0.5 ,  1.  ,  1.5 ,  2.  ,  2.5 ,  3.  ,  3.5 ,  4.  ,\n",
       "        4.5 ,  5.  ,  5.5 ,  6.  ,  6.5 ,  7.  ,  7.5 ,  8.  ,  8.25,\n",
       "        8.5 ,  8.75,  9.  ,  9.5 , 10.  , 10.5 , 11.  , 11.5 , 12.  ,\n",
       "       12.5 , 13.  , 13.5 , 14.  , 14.5 , 15.  , 15.5 , 16.  , 16.5 ,\n",
       "       17.  , 17.5 , 18.  ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using s_gd2 for MDS. None\n"
     ]
    }
   ],
   "source": [
    "emb = new_HeatGeo(knn=5, emb_dim=2).fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_interpolation(pred,true, n_dim=5):\n",
    "    dist_s = ot.dist(pred, true, metric='sqeuclidean')\n",
    "    dist = ot.dist(pred, true, metric='euclidean')\n",
    "\n",
    "    a = np.ones(pred.shape[0])/pred.shape[0]\n",
    "    b = np.ones(true.shape[0])/true.shape[0]\n",
    "    w2 = ot.emd2(a, b, dist_s)\n",
    "    w1 = ot.emd2(a, b, dist)\n",
    "\n",
    "\n",
    "    mmd_r = mmd_rbf(pred, true, gamma=1/n_dim)\n",
    "\n",
    "    mmd_l = mmd_linear(pred, true)\n",
    "\n",
    "    return [w1, w2, mmd_r, mmd_l]\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [\"w1\", \"w2\", \"mmd_r\", \"mmd_l\"]\n",
    "df = pd.DataFrame(columns=col)\n",
    "\n",
    "norm_emb = (emb - emb.mean(0))/emb.std(0)\n",
    "\n",
    "for idx_ho in range(1,len(unique_time[:-1])):\n",
    "    t_init = unique_time[idx_ho-1]\n",
    "    t_hold = unique_time[idx_ho]\n",
    "    t_final = unique_time[idx_ho+1]\n",
    "\n",
    "    mask_init = labels==t_init\n",
    "    mask_hold = labels==t_hold\n",
    "    mask_final = labels==t_final\n",
    "\n",
    "    emb_init = norm_emb[mask_init]\n",
    "    emb_hold = norm_emb[mask_hold]\n",
    "    emb_final = norm_emb[mask_final]\n",
    "\n",
    "    pred_ho = sinkhorn_mccann(emb_init, emb_hold, emb_final, n_points=5000)\n",
    "    res = eval_interpolation(pred_ho, emb_hold)\n",
    "    df_run = pd.DataFrame([res], columns=col)\n",
    "    df = pd.concat([df,df_run], ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metric_emb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
